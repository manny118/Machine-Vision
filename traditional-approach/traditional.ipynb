{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "mubnBSozXlvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os, random, shutil\n",
        "from sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import data\n",
        "from skimage.filters import gaussian\n",
        "import cv2\n",
        "import time\n",
        "from skimage.morphology import disk\n",
        "import statistics\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image  \n",
        "from IPython.display import display # to display images\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import display\n",
        "from skimage.measure import label, regionprops, regionprops_table\n",
        "from skimage import data, exposure\n",
        "from skimage.color import rgb2gray\n",
        "import skimage.data as data\n",
        "import skimage.segmentation as seg\n",
        "import skimage.filters as filters\n",
        "import skimage.draw as draw\n",
        "import skimage.color as color\n",
        "from skimage.color import rgb2hsv # image processing algorithms\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from skimage import data, img_as_float\n",
        "from skimage.segmentation import chan_vese\n",
        "import sys\n",
        "from skimage.filters import threshold_otsu, threshold_local,median\n",
        "from skimage import data, img_as_float, morphology\n",
        "from skimage.segmentation import (morphological_chan_vese,\n",
        "                                  morphological_geodesic_active_contour,\n",
        "                                  inverse_gaussian_gradient,\n",
        "                                  checkerboard_level_set)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import skimage.io as sk\n",
        "from contextlib import suppress\n",
        "import os, random, shutil\n",
        "from skimage import filters\n",
        "import imageio as iio\n",
        "from skimage.filters import threshold_otsu, threshold_local\n",
        "from skimage.filters import threshold_minimum\n",
        "from skimage.filters import threshold_multiotsu\n",
        "import numpy as np\n",
        "from skimage.morphology import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage import measure\n",
        "from skimage.segmentation import random_walker\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "import time\n",
        "\n",
        "from skimage import exposure\n",
        "\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "SV7DTkkxyCuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plots"
      ],
      "metadata": {
        "id": "KeBwXCBDqDdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def histograms(greyimage,imgoriginal):\n",
        "\n",
        "  fig, ax = plt.subplots(2, 2, figsize=(9, 9))\n",
        "  ax[0, 0].set_title('Grey-scaled', fontsize=12)\n",
        "  ax[0,0].imshow(greyimage, cmap=plt.cm.gray)\n",
        "  ax[1, 0].set_title('Grey-scaled Histogram', fontsize=12)\n",
        "  ax[1, 0].set_xlabel('Grey value - Normalised',fontsize=12)\n",
        "  ax[1, 0].set_ylabel('Frequency', fontsize=12)\n",
        "  ax[1,0].hist(greyimage.ravel(), bins=100)\n",
        "  ax[1,0].set_xlim(left=0, right=1)\n",
        "  ax[0, 0].axis('off')\n",
        "  ax[1,0].set_xlim(left=0, right=1)\n",
        "  ax[0,1].imshow(imgoriginal, cmap=plt.cm.gray)\n",
        "  ax[0, 1].axis('off')\n",
        "  ax[1,1].hist(imgoriginal.ravel(), bins=100)\n",
        "  ax[1,1].set_xlim(left=0, right=1)\n",
        "  ax[1, 1].set_xlabel('H value - Normalised',fontsize=12)\n",
        "  ax[1, 1].set_ylabel('Frequency',fontsize=12)\n",
        "  ax[0, 1].set_title('HSV Image - Hue value',fontsize=12)\n",
        "  ax[1, 1].set_title('Hue value histogram',fontsize=12)\n",
        "\n",
        "\n",
        "def binary_clearup(image,binary_global,mask1):\n",
        "  \n",
        "  fig2, ax2 = plt.subplots(1, 4, figsize=(20, 7))\n",
        "  ax2[0].imshow(image)\n",
        "  ax2[0].set_title('Original Image')\n",
        "  ax2[0].axis('off')\n",
        "  ax2[1].imshow(binary_global, cmap=plt.cm.gray)\n",
        "  ax2[1].set_title('Resulting Binary Image')\n",
        "  ax2[1].axis('off')\n",
        "  ax2[2].imshow(mask1, cmap=plt.cm.gray)\n",
        "  ax2[2].set_title('Holes and Small Objects removed')\n",
        "  ax2[2].axis('off')\n",
        "\n",
        "def thresholds(imgoriginal,imgmedian,global_thresh):\n",
        "\n",
        "  fig3, ax3 = plt.subplots(2, 2, figsize=(14, 7))\n",
        "  ax3[0, 0].set_title('HSV Image - H')\n",
        "  ax3[0, 0].imshow(imgoriginal, cmap=plt.cm.gray)\n",
        "  ax3[1,0].hist(imgoriginal.ravel(), bins=100)\n",
        "  ax3[1, 0].set_title('H value Histogram')\n",
        "  ax3[1,0].set_xlim(left=0, right=1)\n",
        "  ax3[0, 0].axis('off')\n",
        "  ax3[0, 1].set_title('Median Filter')\n",
        "  ax3[0,1].imshow(imgmedian, cmap=plt.cm.gray)\n",
        "  ax3[0, 1].axis('off')\n",
        "  ax3[1,1].set_xlim(left=0, right=1)\n",
        "  ax3[1, 1].set_title('Median Filter Histogram')\n",
        "  ax3[1,1].hist(imgmedian.ravel(), bins=100)\n",
        "  ax3[1, 1].axvline(0.04, linewidth=1, color='r',)\n",
        "  ax3[1, 1].axvline(0.9, color='r',linewidth=1,)\n",
        "  ax3[1,1].set_xlim(left=0, right=1)\n",
        "  if global_thresh != 0:\n",
        "    ax3[1, 1].axvline(global_thresh, linewidth=1,color='g')\n",
        "    ax3[1,1].set_xlim(left=0.1, right=0.4)\n",
        "  \n",
        "\n",
        "def watershedseg(image,mask1,labels_ws,path):\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.subplot(141)\n",
        "  plt.imshow(image)\n",
        "  plt.title('Original Image')\n",
        "  plt.axis('off')\n",
        "  plt.subplot(142)\n",
        "  plt.imshow(mask1, cmap=plt.cm.gray)\n",
        "  plt.title('Input Image')\n",
        "  plt.axis('off')\n",
        "  plt.subplot(143)\n",
        "  plt.imshow(labels_ws, cmap='nipy_spectral', interpolation='nearest')\n",
        "  plt.title('Watershed Segmentation')\n",
        "  plt.tight_layout()\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  print(path)"
      ],
      "metadata": {
        "id": "91jlqWY8qJEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions - All Data \n"
      ],
      "metadata": {
        "id": "2ONwvFyPrCdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Upload the dataset to google drive\n",
        "2. Upload the ground truth file into your workspace\n",
        "3. Run the imports section\n",
        "4. Run  the extraction section, you may need to adjust the location of the zip file\n",
        "5. Run the 'Imports', 'Plots', 'Ground Truth' & 'Thresholding' sections to initiate the functions\n",
        "5. Run the 'Run script' section, this will calculate the error for apples counting for detecting 1,2,3 or 4 apples\n",
        "6. If you wish to focus on a particular folder (Number of apples), edit the values of i\n",
        "6. Plots can be added or removed from the threshold_count function, comment these in/out\n"
      ],
      "metadata": {
        "id": "6AHMmK6VTjIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction - All Data"
      ],
      "metadata": {
        "id": "iwYNxHzrVH3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!unzip drive/MyDrive/mldata.zip"
      ],
      "metadata": {
        "id": "D2BSIwhfVZVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ground Truth - All Data\n",
        "\n"
      ],
      "metadata": {
        "id": "_KrdjNI0T9cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ground_truth(applenumber,pathlocation):\n",
        "  images=[]\n",
        "  actualapples=[]\n",
        "  path='mldata/test/'+str(applenumber) \n",
        "# reading the data from the file\n",
        "  with open(pathlocation) as f:\n",
        "    data = f.read()\n",
        "\n",
        "  js = json.loads(data)\n",
        "  images=os.listdir(path)\n",
        "  count=len(images)\n",
        "  for i in range(count):\n",
        "#correction for 3 apple folder\n",
        "    if path=='mldata/test/3':\n",
        "      for j in range(count-1):\n",
        "        if images[j] == '.ipynb_checkpoints':\n",
        "          images.remove(images[j])\n",
        "          count=len(images)\n",
        "          for k in range(count):\n",
        "            actualapples.append(js.get(images[k]))\n",
        "    else:\n",
        "      actualapples.append(js.get(images[i]))\n",
        "\n",
        "\n",
        "  return actualapples,images,path,count"
      ],
      "metadata": {
        "id": "w_zAC6XUUR7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thresholding - All Data"
      ],
      "metadata": {
        "id": "SMa1xfgMVoO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_count(actualapples,images,path):\n",
        "  dir='/content/'+path+'/'\n",
        "  error=[]\n",
        "  detectedapples=[]\n",
        "  for i in range(0,len(images)):\n",
        "    image_path=images[i]\n",
        "    image = iio.imread(dir+image_path)\n",
        "    hsvimage=color.rgb2hsv(image)\n",
        "    greyimage=color.rgb2gray(image)\n",
        "    imgoriginal=hsvimage[:,:,0]\n",
        "    imgmedian=filters.median(imgoriginal)\n",
        "\n",
        "    width=len(image[0])\n",
        "    height=len(image[1])\n",
        "    areaimage=width*height\n",
        "\n",
        "  #boundaries for red apples\n",
        "    binary_global = imgmedian > 0.9\n",
        "    binary_global2 = imgmedian < 0.04\n",
        "    binary_global= np.logical_or(binary_global, binary_global2)\n",
        "    sum2=binary_global.sum()\n",
        "    percentage=sum2/areaimage\n",
        "    global_thresh=0\n",
        "  #if low amount of red in image, look for green using otsu threhsold\n",
        "    if percentage < 0.05:\n",
        "  #boundaries for greenapples\n",
        "      global_thresh = threshold_otsu(imgmedian)\n",
        "      binary_global=(imgmedian<global_thresh)\n",
        "      binary_global2=imgmedian>0.35\n",
        "      binary_global= np.logical_or(binary_global, binary_global2)\n",
        "\n",
        "  #open and close the image to remove objects inside and around the masked area\n",
        "    mask = morphology.remove_small_holes(binary_global,areaimage/100) \n",
        "    mask1=morphology.remove_small_objects(mask,areaimage/100)\n",
        "\n",
        "# Now we want to separate the two objects in image\n",
        "# Generate the markers as local maxima of the distance\n",
        "# to the background\n",
        "    distance = ndimage.distance_transform_edt(mask1)\n",
        "    local_maxi = peak_local_max(\n",
        "    distance, indices=False, labels=mask1, min_distance=12)\n",
        "    markers = measure.label(local_maxi)\n",
        "    labels_ws = watershed(-distance, markers, mask=mask1)\n",
        "  #count number of different regions to find number of apples\n",
        "  \n",
        "    detectedapples.append(len(np.unique(labels_ws))-1)\n",
        "\n",
        "    #optional plots, comment in or out to visualise results\n",
        "    #histograms, shows global the thresholds created on the histogram\n",
        "    #thresholds, displays created thresholds for red and green apples\n",
        "    #binary_clearup, shows results from thresholding and the result of removing small objects/holes\n",
        "    #watershedseg, shows results from watershed segmentation\n",
        "  \n",
        "\n",
        "    #histograms(greyimage,imgoriginal)\n",
        "    #thresholds(imgoriginal,imgmedian,global_thresh)  \n",
        "    #binary_clearup(image,binary_global,mask1)\n",
        "    #watershedseg(image,mask1,labels_ws,path)\n",
        "    \n",
        "  abs_error_percentage=mean_absolute_percentage_error(actualapples, detectedapples)*100\n",
        "  accuracy=100-abs_error_percentage\n",
        "\n",
        "  print ('Absolute error as a percentage: ' + str(abs_error_percentage) + '%')\n",
        "  print ('Accuracy: ' + str(accuracy) + ' %')\n",
        "\n",
        "\n",
        "  return accuracy,abs_error_percentage"
      ],
      "metadata": {
        "id": "UCN1-1RFWagE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Script - All Data"
      ],
      "metadata": {
        "id": "XA8lVexWWkBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here, the extraction and thresholding functions can be run\n",
        "#Comment in the plotting functions within the thresholding function to visualise the results\n",
        "\n",
        "for i in range (1,5):\n",
        "  t0=time.time()\n",
        "  print('Number of apples to predict: ' + str(i))\n",
        "  actualapples,images,path,count=ground_truth(i,'/content/drive/MyDrive/ground_truth.json')\n",
        "  accuracy,error=threshold_count(actualapples,images,path)\n",
        "  t1=time.time()\n",
        "  print('Time to execute: ' +str(t1-t0) + 's\\n')"
      ],
      "metadata": {
        "id": "ulC4vXTfWpwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions -  Sorting Technique"
      ],
      "metadata": {
        "id": "JkekwiQYS4Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Upload the dataset to google drive\n",
        "2. Upload the ground truth file into your workspace. Split the main ground truth based on the predicted number of apples and create subgroups for testing the performance of the proposed algorithm\n",
        "3. Run the imports section\n",
        "4. Run  the extraction section, you may need to adjust the location of the zip file\n",
        "5. Run the 'Plots' and 'Thresholding' sections to initiate the functions\n",
        "5. Run the 'Run script' section, this will calculate the error for apples counting for detecting 1,2,3 or 4 apples\n",
        "6. If you wish to focus on a particular folder (Number of apples), uncomment the \"experimentResults\" line with the desired number of apples\n",
        "6. Plots can be added or removed from the \"countingTradSegmentation\" function, comment these in/out\n"
      ],
      "metadata": {
        "id": "bIE1pPLwrHYl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK3LFD-NoJST"
      },
      "source": [
        "# Extraction -  Sorting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5uYuJo6oMU_",
        "outputId": "6950c640-dd65-4d85-9083-cf40a5051eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Load Google Drive data\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ground Truth -  Sorting"
      ],
      "metadata": {
        "id": "bBsLPmLAw9HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get directory for both json and images. Make sure that all images are located\n",
        "# in 1 folder\n",
        "jsonfile = \"/content/drive/MyDrive/Machine Vision/mldata/mldata/test/ground_truth.json\"\n",
        "fileDirGen = \"/content/drive/MyDrive/Machine Vision/test_data/test_data/counting/images\"\n",
        "fileDir1 = \"/content/drive/MyDrive/Machine Vision/mldata/mldata/test/1\"\n",
        "fileDir2 = \"/content/drive/MyDrive/Machine Vision/mldata/mldata/test/2\"\n",
        "fileDir3 = \"/content/drive/MyDrive/Machine Vision/mldata/mldata/test/3\"\n",
        "fileDir4 = \"/content/drive/MyDrive/Machine Vision/mldata/mldata/test/4\"\n",
        "\n",
        "# Extracting data from ground_truth data\n",
        "with open(jsonfile) as jf:\n",
        "  data = jf.read()\n",
        "\n",
        "# Load JSON file and get file from directory\n",
        "ground_truth = json.loads(data)\n",
        "images_data1 = os.listdir(fileDir1)\n",
        "images_data2 = os.listdir(fileDir2)\n",
        "images_data3 = os.listdir(fileDir3)\n",
        "images_data4 = os.listdir(fileDir4)\n",
        "\n",
        "# Create variables with number of images \n",
        "numberapple_1 = \"1\" \n",
        "numberapple_2 = \"2\"\n",
        "numberapple_3 = \"3\"\n",
        "numberapple_4 = \"4\"\n",
        "\n",
        "def sortingGroundTruth(images, ground_truth, numberApples):\n",
        "  # This function create sorted ground truth based on the number of apples\n",
        "  # Inputs:\n",
        "  # - images: image folder path \n",
        "  # - ground_truth: JSON file with predicted number of apples\n",
        "  # - numberApples: number of apples per images\n",
        "  # Output:\n",
        "  # - gTruthSorted: dictionary with sorted ground truth based on the number of \n",
        "  # apples \n",
        "  gTruthSorted = {}\n",
        "  for i in range(len(images)):\n",
        "    # Check if the image is located in the ground truth\n",
        "    if images[i] in ground_truth.keys():\n",
        "      # Filter the json file based on its value and save in new dictionary\n",
        "      if ground_truth[images[i]] == numberApples:\n",
        "        gTruthSorted[images[i]] = ground_truth[images[i]]\n",
        "\n",
        "  return gTruthSorted\n",
        "\n",
        "# Creating testing groups for experimentation\n",
        "\n",
        "# Maximum number of groups desired\n",
        "group_desired = 21\n",
        "\n",
        "def testSorting(appleDict, nGroups):\n",
        "  # This function aims at create groups of images\n",
        "  # Inputs: \n",
        "  # - appleDict: dictionary with images and actual or predicted values\n",
        "  # - nGroups: number of desired groups\n",
        "  test_array_temp = [] \n",
        "  test_array = []\n",
        "  for i in range(0,nGroups):\n",
        "    # If there are more than 200 images in the directory, create groups of 100 images each\n",
        "    if len(appleDict) >= 200:\n",
        "      if i == 0:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[i:5*(nGroups-1)]))\n",
        "      elif i < nGroups:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[(i*5*(nGroups-1)):(i*5*(nGroups-1))+(5*(nGroups-1))]))\n",
        "      else:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[(i*5*(nGroups-1)):len(appleDict)]))\n",
        "    # If there are between 100 and 200 images in the directory, create groups of 50 images each\n",
        "    elif len(appleDict) >= 100 and len(appleDict) < 200:\n",
        "      if i == 0:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[i:2*(nGroups+4)]))\n",
        "      elif i < nGroups:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[(i*2*(nGroups+4)):(i*2*(nGroups+4))+(2*(nGroups+4))]))\n",
        "      else:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[(i*2*(nGroups+4)):len(appleDict)]))\n",
        "    # If there are less than 30 images in the directory, create groups of 20 images each\n",
        "    else:\n",
        "      if i == 0:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[i:nGroups]))\n",
        "      elif i < nGroups:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[((i*nGroups)):(i*nGroups)+(nGroups)]))\n",
        "      else:\n",
        "        test_array_temp.append(dict(list(appleDict.items())[((i*nGroups)):len(appleDict)]))\n",
        "\n",
        "  # Eliminate any empty dictionary in the array\n",
        "  for i in test_array_temp:\n",
        "    if i != {}:\n",
        "      test_array.append(i)\n",
        "  \n",
        "  if len(test_array) == len(test_array_temp):\n",
        "    return test_array_temp\n",
        "  else:\n",
        "    return test_array"
      ],
      "metadata": {
        "id": "dOhTZwuE2sTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWMdy353woa5"
      },
      "source": [
        "# Thresholding and Results -  Sorting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def countingTradSegmentation(fileDir, imageDataSet, groundTruthApple):\n",
        "  # This function performs approach A, i.e. traditional methods\n",
        "  # Inputs: \n",
        "  # - fileDir: directory where images are located\n",
        "  # - imagesDataSet: image data set\n",
        "  # - groundTruthApple: ground truth with the predicted number of apples\n",
        "  # Output:\n",
        "  # - detectedapples: Dictionary with key being the filename and value being the\n",
        "  # number of detected apples in the image\n",
        "  # - execute_time: executed time for performing approach A on each group\n",
        "  detectedapples = {}\n",
        "  t0 = time.time()\n",
        "  for i in imageDataSet:\n",
        "    if i in groundTruthApple:\n",
        "      # Read image from input file \n",
        "      readImage = iio.imread(fileDir + \"/\" + i)\n",
        "\n",
        "      # Image processing to improve the quality of the image before running \n",
        "      # the watershed algorithm\n",
        "      hsvimage=color.rgb2hsv(readImage)\n",
        "      greyimage=color.rgb2gray(readImage)\n",
        "      imgoriginal=hsvimage[:,:,0]\n",
        "      imgmedian=filters.median(imgoriginal)\n",
        "\n",
        "      width=len(readImage[0])\n",
        "      height=len(readImage[1])\n",
        "      areaimage=width*height\n",
        "\n",
        "      # Boundaries for red apples\n",
        "      binary_global = imgmedian > 0.9\n",
        "      binary_global2 = imgmedian < 0.04\n",
        "      binary_global= np.logical_or(binary_global, binary_global2)\n",
        "      sum2=binary_global.sum()\n",
        "      percentage=sum2/areaimage\n",
        "      global_thresh=0\n",
        "    #if low amount of red in image, look for green using otsu threhsold\n",
        "      if percentage < 0.05:\n",
        "      #boundaries for greenapples\n",
        "        global_thresh = threshold_otsu(imgmedian)\n",
        "        binary_global=(imgmedian<global_thresh)\n",
        "        binary_global2=imgmedian>0.35\n",
        "        binary_global= np.logical_or(binary_global, binary_global2)\n",
        "\n",
        "      # Open and close the image to remove objects inside and around the masked area\n",
        "      mask = morphology.remove_small_holes(binary_global,areaimage/100) \n",
        "      mask1=morphology.remove_small_objects(mask,areaimage/100)\n",
        "\n",
        "      # Now we want to separate the two objects in image\n",
        "      # Generate the markers as local maxima of the distance\n",
        "      # to the background\n",
        "      distance = ndimage.distance_transform_edt(mask1)\n",
        "      local_maxi = peak_local_max(\n",
        "      distance, indices=False, labels=mask1, min_distance=12)\n",
        "      markers = measure.label(local_maxi)\n",
        "      labels_ws = watershed(-distance, markers, mask=mask1)\n",
        "    \n",
        "      #count number of different regions to find number of apples\n",
        "      detectedapples[i] = len(np.unique(labels_ws))-1\n",
        "\n",
        "      #optional plots, comment in or out to visualise results\n",
        "      #histograms, shows global the thresholds created on the histogram\n",
        "      #thresholds, displays created thresholds for red and green apples\n",
        "      #binary_clearup, shows results from thresholding and the result of removing small objects/holes\n",
        "      #watershedseg, shows results from watershed segmentation\n",
        "    \n",
        "      #histograms(greyimage,imgoriginal)\n",
        "      #thresholds(imgoriginal,imgmedian,global_thresh)  \n",
        "      #binary_clearup(readImage,binary_global,mask1)\n",
        "      #watershedseg(readImage,mask1,labels_ws,fileDir)\n",
        "\n",
        "    t1 = time.time()\n",
        "  \n",
        "    executed_time = round(t1-t0,3)\n",
        "\n",
        "  return detectedapples, executed_time\n",
        "\n",
        "\n",
        "def resultsArray(fileDir, appleDict, groundTruth):\n",
        "  # This function allows to store dictionaries with their key being a filename\n",
        "  # and value being the number of detected apple in the image in an array\n",
        "  # Inputs: \n",
        "  # - fileDir: directory where images are located\n",
        "  # - appleDict: Dictionary with key being the filename and value being the\n",
        "  # number of detected apples in the image\n",
        "  # - groundTruthApple: ground truth with the predicted number of apples\n",
        "  # Output:\n",
        "  # - detectedapples_array: array with its items being appleDict\n",
        "  detectedapple_array = []\n",
        "  for i in range(0,len(appleDict)):\n",
        "    detectedapple_array.append(countingTradSegmentation(fileDir, list(appleDict[i].keys()),groundTruth))\n",
        "  \n",
        "  return detectedapple_array"
      ],
      "metadata": {
        "id": "xpPecsb97nh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def threshold_count(actualapples,images,path):\n",
        "  dir='/content/'+path+'/'\n",
        "  error=[]\n",
        "  detectedapples=[]\n",
        "  for i in range(0,len(images)):\n",
        "    image_path=images[i]\n",
        "    image = iio.imread(dir+image_path)\n",
        "    hsvimage=color.rgb2hsv(image)\n",
        "    greyimage=color.rgb2gray(image)\n",
        "    imgoriginal=hsvimage[:,:,0]\n",
        "    imgmedian=filters.median(imgoriginal)\n",
        "\n",
        "    width=len(image[0])\n",
        "    height=len(image[1])\n",
        "    areaimage=width*height\n",
        "\n",
        "  #boundaries for red apples\n",
        "    binary_global = imgmedian > 0.9\n",
        "    binary_global2 = imgmedian < 0.04\n",
        "    binary_global= np.logical_or(binary_global, binary_global2)\n",
        "    sum2=binary_global.sum()\n",
        "    percentage=sum2/areaimage\n",
        "    global_thresh=0\n",
        "  #if low amount of red in image, look for green using otsu threhsold\n",
        "    if percentage < 0.05:\n",
        "  #boundaries for greenapples\n",
        "      global_thresh = threshold_otsu(imgmedian)\n",
        "      binary_global=(imgmedian<global_thresh)\n",
        "      binary_global2=imgmedian>0.35\n",
        "      binary_global= np.logical_or(binary_global, binary_global2)\n",
        "\n",
        "  #open and close the image to remove objects inside and around the masked area\n",
        "    mask = morphology.remove_small_holes(binary_global,areaimage/100) \n",
        "    mask1=morphology.remove_small_objects(mask,areaimage/100)\n",
        "\n",
        "# Now we want to separate the two objects in image\n",
        "# Generate the markers as local maxima of the distance\n",
        "# to the background\n",
        "    distance = ndimage.distance_transform_edt(mask1)\n",
        "    local_maxi = peak_local_max(\n",
        "    distance, indices=False, labels=mask1, min_distance=10)\n",
        "    markers = measure.label(local_maxi)\n",
        "    labels_ws = watershed(-distance, markers, mask=mask1)\n",
        "  #count number of different regions to find number of apples\n",
        "  \n",
        "    detectedapples.append(len(np.unique(labels_ws))-1)\n",
        "\n",
        "    #optional plots, comment in or out to visualise results\n",
        "    #histograms, shows global the thresholds created on the histogram\n",
        "    #thresholds, displays created thresholds for red and green apples\n",
        "    #binary_clearup, shows results from thresholding and the result of removing small objects/holes\n",
        "    #watershedseg, shows results from watershed segmentation\n",
        "  \n",
        "\n",
        "    #histograms(greyimage,imgoriginal)\n",
        "    #thresholds(imgoriginal,imgmedian,global_thresh)  \n",
        "    #binary_clearup(image,binary_global,mask1)\n",
        "    #watershedseg(image,mask1,labels_ws,path)\n",
        "    \n",
        "  abs_error_percentage=mean_absolute_percentage_error(actualapples, detectedapples)*100\n",
        "  accuracy=100-abs_error_percentage\n",
        "\n",
        "  print ('Absolute error as a percentage: ' + str(abs_error_percentage) + '%')\n",
        "  print ('Accuracy: ' + str(accuracy) + ' %')\n",
        "\n",
        "\n",
        "  return accuracy,abs_error_percentage\n",
        "  '''"
      ],
      "metadata": {
        "id": "xHacMEBjwre1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a84d7c07-cfb8-49df-f1a6-4cee21b6ae39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef threshold_count(actualapples,images,path):\\n  dir='/content/'+path+'/'\\n  error=[]\\n  detectedapples=[]\\n  for i in range(0,len(images)):\\n    image_path=images[i]\\n    image = iio.imread(dir+image_path)\\n    hsvimage=color.rgb2hsv(image)\\n    greyimage=color.rgb2gray(image)\\n    imgoriginal=hsvimage[:,:,0]\\n    imgmedian=filters.median(imgoriginal)\\n\\n    width=len(image[0])\\n    height=len(image[1])\\n    areaimage=width*height\\n\\n  #boundaries for red apples\\n    binary_global = imgmedian > 0.9\\n    binary_global2 = imgmedian < 0.04\\n    binary_global= np.logical_or(binary_global, binary_global2)\\n    sum2=binary_global.sum()\\n    percentage=sum2/areaimage\\n    global_thresh=0\\n  #if low amount of red in image, look for green using otsu threhsold\\n    if percentage < 0.05:\\n  #boundaries for greenapples\\n      global_thresh = threshold_otsu(imgmedian)\\n      binary_global=(imgmedian<global_thresh)\\n      binary_global2=imgmedian>0.35\\n      binary_global= np.logical_or(binary_global, binary_global2)\\n\\n  #open and close the image to remove objects inside and around the masked area\\n    mask = morphology.remove_small_holes(binary_global,areaimage/100) \\n    mask1=morphology.remove_small_objects(mask,areaimage/100)\\n\\n# Now we want to separate the two objects in image\\n# Generate the markers as local maxima of the distance\\n# to the background\\n    distance = ndimage.distance_transform_edt(mask1)\\n    local_maxi = peak_local_max(\\n    distance, indices=False, labels=mask1, min_distance=10)\\n    markers = measure.label(local_maxi)\\n    labels_ws = watershed(-distance, markers, mask=mask1)\\n  #count number of different regions to find number of apples\\n  \\n    detectedapples.append(len(np.unique(labels_ws))-1)\\n\\n    #optional plots, comment in or out to visualise results\\n    #histograms, shows global the thresholds created on the histogram\\n    #thresholds, displays created thresholds for red and green apples\\n    #binary_clearup, shows results from thresholding and the result of removing small objects/holes\\n    #watershedseg, shows results from watershed segmentation\\n  \\n\\n    #histograms(greyimage,imgoriginal)\\n    #thresholds(imgoriginal,imgmedian,global_thresh)  \\n    #binary_clearup(image,binary_global,mask1)\\n    #watershedseg(image,mask1,labels_ws,path)\\n    \\n  abs_error_percentage=mean_absolute_percentage_error(actualapples, detectedapples)*100\\n  accuracy=100-abs_error_percentage\\n\\n  print ('Absolute error as a percentage: ' + str(abs_error_percentage) + '%')\\n  print ('Accuracy: ' + str(accuracy) + ' %')\\n\\n\\n  return accuracy,abs_error_percentage\\n  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def experimentResults(detectedList, gtList, numberapples):\n",
        "  # This function helps to assess the performance of approach A\n",
        "  # Inputs: \n",
        "  # - detectedList: List of dictionaries with key being the filename and value\n",
        "  # being the number of detected apples in the image\n",
        "  # - gtList: ground truth with the desired predicted number of apples\n",
        "  # - numberapples: number of apples per image\n",
        "\n",
        "  print(\"Results - Counting \" + numberapples + \" apple(s)\")\n",
        "\n",
        "  for i in range(0, len(detectedList)):\n",
        "    # Separate filename from number of detected/predicted number of apples\n",
        "    keys_detected = list(detectedList[i][0].keys())\n",
        "    keys_actual = list(gtList[i].keys())\n",
        "    values_detected = list(detectedList[i][0].values())\n",
        "    values_actual = list(gtList[i].values())\n",
        "\n",
        "    # Calculate the mean absolute error\n",
        "    error_temp = {}\n",
        "    accuracy_temp = {}\n",
        "    for j in range(len(values_detected)):\n",
        "      error_temp[keys_detected[j]] = (abs(int(values_actual[j])-int(values_detected[j]))/int(values_actual[j]))\n",
        "      accuracy_temp[keys_detected[j]] = 1 - error_temp[keys_detected[j]]\n",
        "    \n",
        "    # Obtain the confusion matrix\n",
        "    # It is important to reformate the data so that we can recreate a True and False scenario\n",
        "    values_detected_bool = []\n",
        "    values_actual_bool = []\n",
        "    for x in range(0, len(values_detected)):\n",
        "      # If the number of detected apples is equal to the number of apples in the image,\n",
        "      # return True, i.e. \"Yes\", else return False, i.e. \"No\"\n",
        "      if values_detected[x] == int(numberapples):\n",
        "        values_detected_bool.append(\"Yes\")\n",
        "      else:\n",
        "        values_detected_bool.append(\"No\")\n",
        "\n",
        "    # If the number of predicted apples is equal to the number of apples in the image,\n",
        "    # return True, i.e. \"Yes\", else return False, i.e. \"No\"\n",
        "    # For this step, it is expected to get a list of \"Yes\" since it is the ground truth\n",
        "    for k in range(0, len(values_actual)):\n",
        "      if values_actual[k] == numberapples:\n",
        "        values_actual_bool.append(\"Yes\")\n",
        "      else:\n",
        "        values_actual_bool.append(\"No\")\n",
        "\n",
        "\n",
        "    print(\"-----Sample \" + str(i+1) + \"------------\")   \n",
        "\n",
        "    print(\"Confusion Matrix\")\n",
        "\n",
        "    cf_matrix = metrics.confusion_matrix(values_detected_bool, values_actual_bool)\n",
        "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cf_matrix, display_labels = [False, True])\n",
        "\n",
        "    cm_display.plot()\n",
        "    plt.show()\n",
        "\n",
        "    # Extract TP and FN values from confusion matrix and derive the TPR/accuracy\n",
        "    TP = cf_matrix[1][1]\n",
        "    FN = cf_matrix[0][1]\n",
        "    TPR = round(100*(TP/(TP+FN)),3)\n",
        "\n",
        "    print(\"---------------------------\")\n",
        "\n",
        "    print(\"Results of confusion matrix\")\n",
        "    print(\"---------------------------\")\n",
        "    print(\"TP =\", TP)\n",
        "    print(\"FN =\", FN)\n",
        "    print(\"TPR =\", TPR)\n",
        "    print(\"---------------------------\")\n",
        "\n",
        "    print(\"Mean Error = \", round(statistics.mean(error_temp.values()),3))\n",
        "\n",
        "    print(\"---------------------------\")\n",
        "\n",
        "    print(\"Mean Accuracy = \", round(statistics.mean(accuracy_temp.values()),3))\n",
        "\n",
        "    print(\"---------------------------\")\n",
        "\n",
        "    print(\"Execution time = \", round(detectedList[i][1],3))\n",
        "\n",
        "    print(\"---------------------------\")"
      ],
      "metadata": {
        "id": "ATJRHBVI-UpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run script -  Sorting"
      ],
      "metadata": {
        "id": "8oeskVDEq-Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, the extraction, thresholding and results functions can be run\n",
        "# Comment in the plotting functions within the thresholding function to visualise the results\n",
        "\n",
        "# 1- Extraction \n",
        "# 1-a) Sort JSON file based on the number of apples\n",
        "images1apple = sortingGroundTruth(images_data1, ground_truth, numberapple_1)\n",
        "images2apple = sortingGroundTruth(images_data2, ground_truth, numberapple_2)\n",
        "images3apple = sortingGroundTruth(images_data3, ground_truth, numberapple_3)\n",
        "images4apple = sortingGroundTruth(images_data4, ground_truth, numberapple_4)\n",
        "\n",
        "# 1-b) Split ground truths in different groups to test performance of the \n",
        "# proposed algorithm on different groups. Save these groups in arrays\n",
        "test_1apple = testSorting(images1apple, group_desired)\n",
        "test_2apple = testSorting(images2apple, group_desired)\n",
        "test_3apple = testSorting(images3apple, group_desired)\n",
        "test_4apple = testSorting(images4apple, group_desired)\n",
        "\n",
        "# 2 - Thresholding\n",
        "detected1apple = resultsArray(fileDir1, test_1apple, images1apple)\n",
        "detected2apple = resultsArray(fileDir2, test_2apple, images2apple)\n",
        "detected3apple = resultsArray(fileDir3, test_3apple, images3apple)\n",
        "detected4apple = resultsArray(fileDir4, test_4apple, images4apple)\n",
        "\n",
        "# 3- Results\n",
        "# For get the results for a specific folder, i.e. with the desired number of\n",
        "# apples, uncomment one of the following lines\n",
        "experimentResults(detected1apple, test_1apple, numberapple_1)\n",
        "#experimentResults(detected2apple, test_2apple, numberapple_2)\n",
        "#experimentResults(detected3apple, test_3apple, numberapple_3)\n",
        "#experimentResults(detected4apple, test_4apple, numberapple_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fJ6BxSD88W1",
        "outputId": "aa4eb431-5c68-49b1-ffc8-aaaeca69dee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-7951a0662b42>:52: FutureWarning: indices argument is deprecated and will be removed in version 0.20. To avoid this warning, please do not use the indices argument. Please see peak_local_max documentation for more details.\n",
            "  local_maxi = peak_local_max(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results - Counting 1 apple(s)\n",
            "-----Sample 1------------\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZbElEQVR4nO3deZQc5Xnv8e9vBm0IBAgJIWQWEQjLxUEImUUERSxmie0D5NrGGBuISTAJhCTYPjYOJybmhsN1bJPEBjtiOcgxqy5gwLERGMwRcFkkiEALq7HAaEELixAgaZYnf9TbUs941F0z09PVo/59zqmjruqqt5+ZZh7erd5SRGBmZpmWogMwM2skTopmZmWcFM3MyjgpmpmVcVI0MyuzTdEBDIShGhbDGVl0GNYLGyf4+xpsNix9Y3VEjO1PGSceMzLWvNWR69ynn9swOyJO6s/n5bFVJsXhjORwHVd0GNYLv73oyKJDsF76zde/8lp/y1jzVgdPzd4j17mt418e09/Py2OrTIpmNjgE0Eln0WF04aRoZoUJgrbI13yuFydFMyuUa4pmZkkQdDTYrcZOimZWqE6cFM3MgGygpcNJ0cxsM9cUzcySANrcp2hmlgnCzWczs00COhorJzopmllxsjtaGouTopkVSHSgooPowknRzAqTDbQ4KZqZAaV5ik6KZmabdLqmaGaWcU3RzKxMIDoa7KkoTopmVig3n83MkkBsjNaiw+jCSdHMCpNN3nbz2cxsk0YbaGmsFG1mTSVCdERLrq0SScMlPSXpWUmLJP1TOj5R0pOSXpF0m6Sh1WJyUjSzQnWiXFsVG4BjI+JgYBJwkqQjgP8LXBUR+wBvA+dWK8hJ0cwKkw20bJNrq1hOZl3aHZK2AI4F/l86PhM4tVpMTopmVpjSQEueDRgjaV7Zdl55WZJaJc0HVgIPAL8B3omI9nTKG8CEajF5oMXMCtWRf57i6oiYsqU3I6IDmCRpR+AuYP++xOOkaGaFGYg7WiLiHUm/Bo4EdpS0TaotfgRYWu16N5/NrFCd0ZJrq0TS2FRDRNII4OPA88CvgU+n084G7q4Wj2uKZlaYbEGImtTNxgMzJbWSVfZuj4ifS1oM3Crp/wD/DVxfrSAnRTMrTCDaanCbX0Q8BxzSw/FXgcN6U5aTopkVJoKqE7PrzUnRzAqUa2J2XTkpmllhAtcUzcy68CKzZmZJIC8ya2ZWkj3itLHSUGNFY2ZNRg23nqKTopkVJqDq3Sr15qRoZoVyTdHMLImQa4pmZiXZQIuf5mdmlsiTt83MSrKBFvcpmplt4jtazMwS39FiZtZNp2uKZmaZCGjrdFI0MwNKzWcnRTOzTXxHi/XJlOlrOf/yZbS2BL+8ZTS3/3Bc0SFZN1dM/TXHTHiNNetH8Ml7T990/Iv7L+DM/RbREeLhN/bgX545ssAoG0tTTcmR1AEsKDt0akQs2cK56yJiu4GKZbBraQkuuGIpl3xub1YvH8IPfvEyT8zegddfHl50aFbmzlf246cvHMR3jnpo07HDxy3luN2X8Kl7P0NbZyujh39YYISNqLmazx9GxKQBLL9p7HfIByxbMpQVrw8D4OG7d+TIE991Umww81buxoSRa7scO2O/RcxYeAhtndmtbG+tH1FEaA2t0Z7RUrcULWk7SQ9KekbSAkmn9HDOeElzJM2XtFDS0en4CZIeT9fOktRUtcqdd21j1bKhm/ZXLx/CmPFtBUZkeU0c9S5TdlnOrJPv5Kcn3M1Hd15ZdEgNJRt9bs211ctAJsURKbnNl3QXsB44LSImA8cA35PU/X8RnwdmpxrmwcB8SWOAS4Hj07XzgIu7f5ik8yTNkzSvjQ0D+GOZ5deqTnYYtoHP/PI0vvP0EfzrtAfIetIMNk/ezrNVIml3Sb+WtFjSIkl/m45fJmlpWS7602ox1a35LGkIcIWkaUAnMAEYB6wou2YucEM692cRMV/SnwAHAo+lHDoUeLz7h0XEDGAGwCiN3qr+q1uzYghjd9u4aX/M+DZWLx9SYESW14oPtuP+1yYC4rk14wjETsPW8/YGN6NLatR8bge+EhHPSNoeeFrSA+m9qyLiu3kLqmcP55nAWODQlCzfBLp0ikXEHGAasBS4UdJZgIAHImJS2g6MiHPrGHfhXpy/LRMmbmTc7hvYZkgn0095hyfu36HosCyHX/1uLw7fdRkAe23/DkNaOnh7g/uCS0qjz/2tKUbE8oh4Jr1+D3ierOLVa/WckrMDsDIi2iQdA+zZ/QRJewJvRMS1koYBk4F/Bq6WtE9EvCJpJDAhIl6qY+yF6uwQV//DBK64+VVaWuH+W0fz2kv+w2o03z/6Vxw2bhk7DV/PnP/9n/z7s1O445X9uWLqw/z8U7fR1tnK1x87FhpsYKFovRh9HiNpXtn+jNRC7ELSXsAhwJPAUcCFqYI1j6w2+XalD6lnUrwJuFfSArLgXujhnOnA1yS1AeuAsyJilaRzgFtSooSsj7FpkiLA3IdGMfehUUWHYRVc/MjxPR7/2qPH1TmSwSNCtOdPiqsjYkqlE9Ig7B3A30XEWkk/Ai4nq5ReDnwP+FKlMgYsKXafdxgRq4EeZ62Wzo2ImcDMHt5/CPjYAIRpZgWr1eTtNBZxB3BTRNwJEBFvlr1/LfDzauX4jhYzK0yt7mhJM1muB56PiO+XHR8fEcvT7mnAwmplOSmaWaFqVFM8CvgisEDS/HTsm8AZkiaR5d8lwJerFeSkaGaFqdUisxHxKD2PYP2it2U5KZpZoRrtNj8nRTMrTAS0e5FZM7PNmmbpMDOzavzgKjOzbsJJ0cxsMw+0mJklEe5TNDMrIzo8+mxmtpn7FM3MkqZ6mp+ZWVWR9Ss2EidFMyuUR5/NzJLwQIuZWVduPpuZlfHos5lZEuGkaGbWhafkmJmVcZ+imVkSiE6PPpuZbdZgFUUnRTMrkAdazMy6abCqopOimRVq0NQUJf2ACjk8Ii4akIjMrGkE0NnZ/6QoaXfgJ8C4VOyMiPg3SaOB24C9gCXAZyPi7UplVaopzut3pGZmlQRQm5piO/CViHhG0vbA05IeAM4BHoyIKyV9A/gG8PVKBW0xKUbEzPJ9SdtGxAf9Dt3MrEwt5ilGxHJgeXr9nqTngQnAKcD0dNpM4GGqJMWqE4QkHSlpMfBC2j9Y0jV9Dd7MrIvIucEYSfPKtvN6Kk7SXsAhwJPAuJQwAVaQNa8ryjPQ8q/AicA9ABHxrKRpOa4zM6tCvRloWR0RUyqWJm0H3AH8XUSslTaXHREhqWq9NNdU8oj4XbdDHXmuMzOrKn9NsSJJQ8gS4k0RcWc6/Kak8en98cDKauXkSYq/kzQVCElDJH0VeD7HdWZmlQVEp3JtlSirEl4PPB8R3y976x7g7PT6bODuaiHlaT6fD/wbWaflMmA2cEGO68zMcqjJ6PNRwBeBBZLmp2PfBK4Ebpd0LvAa8NlqBVVNihGxGjiz77GamVVQm9HnR9lydj2uN2XlGX3eW9K9klZJWinpbkl79+ZDzMy2qEZ9irWSp0/xZuB2YDywGzALuGUggzKzJlGavJ1nq5M8SXHbiPjPiGhP20+B4QMdmJk1h4h8W71Uuvd5dHr5y3R7zK1kef104Bd1iM3MmkEN7n2upUoDLU+TJcFSxF8uey+ASwYqKDNrHtWnU9dXpXufJ9YzEDNrQnUeRMkj13qKkg4CDqSsLzEifjJQQZlZs6jvIEoeVZOipG+RrTJxIFlf4snAo2Rrl5mZ9U+D1RTzjD5/mmzy44qI+HPgYGCHAY3KzJpHZ86tTvI0nz+MiE5J7ZJGkd1QvfsAx2VmzaB2i8zWTJ6kOE/SjsC1ZCPS64DHBzQqM2sag2b0uSQi/jq9/LGk+4BREfHcwIZlZk1jsCRFSZMrvRcRzwxMSGZmxalUU/xehfcCOLbGsVgTe+msHxUdgvVSa8UnneQ3aJrPEXFMPQMxsyYUDKrb/MzMBt5gqSmamdXDoGk+m5nVRYMlxTwrb0vSFyT9Y9rfQ9JhAx+amTWFQbjy9jXAkcAZaf894OoBi8jMmoYi/1YveZrPh0fEZEn/DRARb0saOsBxmVmzGISjz22SWkkVWEljqevt2Wa2NWu0gZY8zed/B+4CdpH0z2TLhl0xoFGZWfNosD7FPPc+3yTpabLlwwScGhHPD3hkZrb1q2F/oaQbgE8CKyPioHTsMuAvgVXptG9GRMVnTOUZfd4D+AC4F7gHeD8dMzPrv9rVFG8ETurh+FURMSltVR+6l6dP8b/Y/ACr4cBE4EXgf+UK08ysAtVohCIi5kjaq7/lVK0pRsRHI+KP0r/7Aofh9RTNrP7GSJpXtp2X87oLJT0n6QZJO1U7Oc9ASxdpybDDe3udmVmP8jefV0fElLJtRo7SfwT8ATAJWE7l1b+AfA+uurhstwWYDCzLEYyZWWUDPDE7It4svZZ0LfDzatfk6VPcvux1O1kf4x29js7MrCcDmBQljY+I5Wn3NGBhtWsqJsU0aXv7iPhqDeIzM/t9tZuScwvZ45jHSHoD+BYwXdKk9ClLgC9XK6fS4wi2iYh2SUfVJGIzs25ETUefz+jh8PW9LadSTfEpsv7D+ZLuAWYB75cFcGdvP8zMrIs6L/aQR54+xeHAGrJnspTmKwbgpGhm/TeIkuIuaeR5IZuTYUmD/RhmNmg1WDaplBRbge3omgxLGuzHMLPBajA1n5dHxLfrFomZNadBlBQba+VHM9v6RO1Gn2ulUlI8rm5RmFnzGiw1xYh4q56BmFlzGkx9imZmA89J0cwsqfOjBvJwUjSzwgg3n83MunBSNDMr56RoZlbGSdHMLBmkq+SYmQ0cJ0Uzs80G021+ZmYDzs1nM7MST942M+vGSdHMLOM7WszMulFnY2VFJ0UzK04D9im2FB2AmTU3Rb6tajnSDZJWSlpYdmy0pAckvZz+3alaOU6KZlasyLlVdyNwUrdj3wAejIh9gQfTfkVOimZWqFrVFCNiDtD9iQGnADPT65nAqdXKcZ+imRUrf5/iGEnzyvZnRMSMKteMi4jl6fUKYFy1D3FSNLPi9O5pfqsjYkqfPyoipOp1TjefzawwpXmKtWg+b8GbksYDpH9XVrvASdHMihWRb+ube4Cz0+uzgburXeCkaGaFquGUnFuAx4H9JL0h6VzgSuDjkl4Gjk/7FblPcZCYMn0t51++jNaW4Je3jOb2H1btL7Y627hefOXP9qFtYwsd7XD0J97lrK+t2PT+NZdOYPato7n7lQUFRtlgajh5OyLO2MJbx/WmnLokRUk7k80RAtgV6ABWpf3DImJjPeIYrFpagguuWMoln9ub1cuH8INfvMwTs3fg9ZeHFx2alRkyLPjOrN8wYmQn7W1w8an78rFj13LAoR/w0rMjWPdua9EhNqRGW0+xLs3niFgTEZMiYhLwY+Cq0n5EbJTkGmsF+x3yAcuWDGXF68Nob2vh4bt35MgT3y06LOtGghEjs7/w9jbR0SYk6OiAay/fjXMvXVZwhI1Jnfm2eiksGUm6EVgPHAI8JmktsC4ivpveXwh8MiKWSPoCcBEwFHgS+OuI6Cgm8vrbedc2Vi0buml/9fIh7D/5gwIjsi3p6IALT9yPZUuG8qlzVrP/5A+467oxHHnCWnYe1150eI0n6M8gyoAoeqDlI8DUiLh4SydIOgA4HTgq1TQ7gDN7OO88SfMkzWtjw4AFbFZJayv86FcvctPTi3lx/rYseGIkj9y7I6d8aVX1i5vUAE/J6bWim62zctT4jgMOBeZKAhhBD3ON0sz2GQCjNLqx/tfTT2tWDGHsbpu7XceMb2P18iEFRmTVbLdDBwdPXcezj23HsiXD+POpBwKw4cMWzpl6ADf+/+cLjrCBNNhfa9FJ8f2y1+10rbmWRhEEzIyIS+oWVYN5cf62TJi4kXG7b2DNiiFMP+Udrrxgz6LDsm7eWdPKNttkCXHDh+KZOdvz2QtWcuuzizadc8o+H3VCLONFZitbAnwSQNJkYGI6/iBwt6SrImKlpNHA9hHxWjFh1l9nh7j6HyZwxc2v0tIK9986mtde8shzo3nrzSF892/3oLNTdHbCtE+9wxEfX1t0WI0twovMVnAHcJakRWSDKS8BRMRiSZcC90tqAdqAC4CmSYoAcx8axdyHRhUdhlWw94HrueaBlyqe4zmKPWisnFj/pBgRl23h+IfACVt47zbgtgEMy8wK4uazmVlJAG4+m5mVaayc6KRoZsVy89nMrIxHn83MShrwEadOimZWmGzydmNlRSdFMytWgy0d5qRoZoVyTdHMrMR9imZm5Xzvs5lZV24+m5kl0XjPaHFSNLNiuaZoZlamsXKik6KZFUudtWk/S1oCvEf2HKf2iJjSl3KcFM2sOEGtJ28fExGr+1OAk6KZFUZEw03eLvoRp2bW7CLybTCm9BjjtJ3XvSSyx5Y83cN7ubmmaGbFyl9TXF2ln/CPI2KppF2AByS9EBFzehuOa4pmVpxSn2KerVpREUvTvyuBu4DD+hKSk6KZFUqdnbm2imVIIyVtX3pN9hC8hX2Jx81nMytQ1Gry9jjgLkmQ5bWbI+K+vhTkpGhmxQlqkhQj4lXg4H4XhJOimRXN9z6bmW3WaPMUnRTNrFhOimZmSQR0NFb72UnRzIrlmqKZWRknRTOzJAA/o8XMrCQg3KdoZpYJPNBiZtaF+xTNzMo4KZqZldRsQYiacVI0s+IEUKMHV9WKk6KZFcs1RTOzEt/mZ2a2WUB4nqKZWRnf0WJmVsZ9imZmSYRHn83MunBN0cysJIiOjqKD6MJJ0cyK46XDzMy6abApOS1FB2BmzSuA6IxcWzWSTpL0oqRXJH2jrzE5KZpZcSItMptnq0BSK3A1cDJwIHCGpAP7EpKbz2ZWqBoNtBwGvBIRrwJIuhU4BVjc24IUDTYcXguSVgGvFR3HABkDrC46COuVrfU72zMixvanAEn3kf1+8hgOrC/bnxERM1I5nwZOioi/SPtfBA6PiAt7G9NWWVPs7xfVyCTNi4gpRcdh+fk727KIOKnoGLpzn6KZbQ2WAruX7X8kHes1J0Uz2xrMBfaVNFHSUOBzwD19KWirbD5v5WYUHYD1mr+zARYR7ZIuBGYDrcANEbGoL2VtlQMtZmZ95eazmVkZJ0UzszLuUyyYpA5gQdmhUyNiyRbOXRcR29UlMKtI0s7Ag2l3V6ADWJX2D4uIjYUEZv3mPsWC9SbROSk2JkmXAesi4rtlx7aJiPbiorK+cvO5wUjaTtKDkp6RtEDSKT2cM17SHEnzJS2UdHQ6foKkx9O1syQ5gdaRpBsl/VjSk8B3JF0m6atl7y+UtFd6/QVJT6Xv8D/SvbvWAJwUizci/WHMl3QX2W1Mp0XEZOAY4HuS1O2azwOzI2IScDAwX9IY4FLg+HTtPODi+v0YlnwEmBoRW/zdSzoAOB04Kn2HHcCZdYrPqnCfYvE+TH8YAEgaAlwhaRrQCUwAxgEryq6ZC9yQzv1ZRMyX9Cdkq4M8lnLoUODxOv0MttmsiKi2wsFxwKHA3PRdjQBWDnRglo+TYuM5ExgLHBoRbZKWkN0Iv0lEzElJ8xPAjZK+D7wNPBARZ9Q7YOvi/bLX7XRtjZW+RwEzI+KSukVlubn53Hh2AFamhHgMsGf3EyTtCbwZEdcC1wGTgSeAoyTtk84ZKekP6xi3/b4lZN8NkiYDE9PxB4FPS9olvTc6fafWAFxTbDw3AfdKWkDWL/hCD+dMB74mqQ1YB5wVEasknQPcImlYOu9S4KWBD9m24A7gLEmLgCdJ30VELJZ0KXC/pBagDbiArXe5u0HFU3LMzMq4+WxmVsZJ0cysjJOimVkZJ0UzszJOimZmZZwUm5SkjrJ7p2dJ2rYfZd2YnqaGpOsqPW9X0nRJU/vwGUvSrYy5jnc7Z10vP6vLPcvWXJwUm9eHETEpIg4CNgLnl78pqU9zWCPiLyKi0rN2pwO9Topm9eKkaACPAPukWtwjku4BFktqlfQvkuZKek7SlwGU+aGkFyX9CtilVJCkhyVNSa9PSiv2PJtW/tmLLPn+faqlHi1prKQ70mfMlXRUunZnSfdLWiTpOrJb4yqS9DNJT6drzuv23lXp+IOSxqZjfyDpvnTNI5L2r8Uv0wY339HS5FKN8GTgvnRoMnBQRPw2JZZ3I+Jj6S6ZxyTdDxwC7Ee2AMU4YDFwQ7dyxwLXAtNSWaMj4i1JP6Zs7UFJNwNXRcSjkvYge/DQAcC3gEcj4tuSPgGcm+PH+VL6jBFkiy3cERFrgJHAvIj4e0n/mMq+kOyBUudHxMuSDgeuAY7tw6/RtiJOis1rhKT56fUjwPVkzdqnIuK36fgJwB+V+gvJ7sveF5gG3JJWg1km6aEeyj8CmFMqKyLe2kIcxwMHlq2ONiqtAzkN+LN07X9JejvHz3SRpNPS691TrGvIVhu6LR3/KXBn+oypwKyyzx6GNT0nxebVZckygJQcyld5EfA3ETG723l/WsM4WoAjImJ9D7HkJmk6WYI9MiI+kPQw3VYXKhPpc9/p/jswc5+iVTIb+Ku0biOS/lDSSGAOcHrqcxxPthhud08A0yRNTNeOTsffA7YvO+9+4G9KO5JKSWoO2WK6SDoZ2KlKrDsAb6eEuD9ZTbWkBSjVdj9P1ixfC/xW0mfSZ0jSwVU+w5qAk6JVch1Zf+EzkhYC/0HWurgLeDm99xN6WMw2IlYB55E1VZ9lc/P1XuC00kALcBEwJQ3kLGbzKPg/kSXVRWTN6NerxHofsI2k54EryZJyyfvAYelnOBb4djp+JnBuim8R8HuPfrDm41VyzMzKuKZoZlbGSdHMrIyToplZGSdFM7MyTopmZmWcFM3MyjgpmpmV+R8bBNvi6FXgdQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "Results of confusion matrix\n",
            "---------------------------\n",
            "TP = 34\n",
            "FN = 16\n",
            "TPR = 68.0\n",
            "---------------------------\n",
            "Mean Error =  0.32\n",
            "---------------------------\n",
            "Mean Accuracy =  0.68\n",
            "---------------------------\n",
            "Execution time =  0.636\n",
            "---------------------------\n",
            "-----Sample 2------------\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "Results of confusion matrix\n",
            "---------------------------\n",
            "TP = 37\n",
            "FN = 13\n",
            "TPR = 74.0\n",
            "---------------------------\n",
            "Mean Error =  0.34\n",
            "---------------------------\n",
            "Mean Accuracy =  0.66\n",
            "---------------------------\n",
            "Execution time =  0.419\n",
            "---------------------------\n",
            "-----Sample 3------------\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "Results of confusion matrix\n",
            "---------------------------\n",
            "TP = 26\n",
            "FN = 24\n",
            "TPR = 52.0\n",
            "---------------------------\n",
            "Mean Error =  0.48\n",
            "---------------------------\n",
            "Mean Accuracy =  0.52\n",
            "---------------------------\n",
            "Execution time =  0.27\n",
            "---------------------------\n",
            "-----Sample 4------------\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "Results of confusion matrix\n",
            "---------------------------\n",
            "TP = 8\n",
            "FN = 5\n",
            "TPR = 61.538\n",
            "---------------------------\n",
            "Mean Error =  0.385\n",
            "---------------------------\n",
            "Mean Accuracy =  0.615\n",
            "---------------------------\n",
            "Execution time =  0.072\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Here, the extraction and thresholding functions can be run\n",
        "#Comment in the plotting functions within the thresholding function to visualise the results\n",
        "\n",
        "for i in range (1,5):\n",
        "  t0=time.time()\n",
        "  print('Number of apples to predict: ' + str(i))\n",
        "  actualapples,images,path,count=ground_truth(i,'/content/drive/MyDrive/ground_truth.json')\n",
        "  accuracy,error=threshold_count(actualapples,images,path)\n",
        "  t1=time.time()\n",
        "  print('Time to execute: ' +str(t1-t0) + 's\\n')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0as7NjFfwvxi",
        "outputId": "3217007f-ee1e-492f-8df1-be673625d527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of apples to predict: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-caf6954fe152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of apples to predict: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mactualapples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Machine Vision/test_data/test_data/counting/ground_truth.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualapples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-d442ed7c4bb5>\u001b[0m in \u001b[0;36mground_truth\u001b[0;34m(applenumber, pathlocation)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mldata/test/1'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mubnBSozXlvX",
        "KeBwXCBDqDdE",
        "2ONwvFyPrCdw",
        "iwYNxHzrVH3D",
        "_KrdjNI0T9cV",
        "SMa1xfgMVoO9",
        "XA8lVexWWkBW",
        "JkekwiQYS4Tp",
        "OK3LFD-NoJST",
        "bBsLPmLAw9HX",
        "zWMdy353woa5",
        "8oeskVDEq-Tw"
      ],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}